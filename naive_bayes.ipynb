{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this lab is to build a model using Naive Bayes to classify movie reviews into positive or negative, and then test the classifier on new movie reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "Our input for this problem are two groups of movie reviews, pos and neg, where each review is stored in a separate text file. The dataset can be downloaded from here: [movies_reviews](https://drive.google.com/file/d/1BzgcXlSRqFj1RoadBupx_OQm322-rHTt/view).\n",
    "\n",
    "The dataset is from the following publication: ''Thumbs up? Sentiment Classification using Machine Learning Techniques''. Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. Proceedings of EMNLP, pp. 79--86, 2002."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Read files into arrays \n",
    "We first read files and store their content into 2 string arrays, where each element is a string of one movie review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 1000, 5)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_dir = \"../data_set/movies_reviews\"\n",
    "pos_entries = os.listdir(data_dir+\"/pos\")\n",
    "neg_entries = os.listdir(data_dir+\"/neg\")\n",
    "test_entries = os.listdir(data_dir+\"/test\")\n",
    "\n",
    "pos_ls = []\n",
    "for file in pos_entries:\n",
    "    if not file.startswith('.'):\n",
    "        file = data_dir + \"/pos/\" + file\n",
    "        text = open(file,\"r\").read()\n",
    "        pos_ls.append(text)\n",
    "    \n",
    "neg_ls = []\n",
    "for file in neg_entries:\n",
    "    if not file.startswith('.'):\n",
    "        file = data_dir + \"/neg/\" + file\n",
    "        text = open(file,\"r\").read()\n",
    "        neg_ls.append(text)\n",
    "        \n",
    "test_ls = []\n",
    "for file in test_entries:\n",
    "    if not file.startswith('.'):\n",
    "        file = data_dir + \"/test/\" + file\n",
    "        text = open(file,\"r\").read()\n",
    "        test_ls.append(text)\n",
    "    \n",
    "len(pos_ls),len(neg_ls),len(test_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Vectorization of documents\n",
    "To convert the words in each document into a vector of word occurrences, we use use a special class from <code>sklearn.feature_extraction.text</code> called <code>CountVectorizer</code>. It works by first tokenizing, i.e, assigning the unique numbers to each of the words in a text, and then counting the occurrence of these numbers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we apply the vectorization, we need to first find out the stopped word that are very commonly used in all documents no matter the class of the document, given in file \"stop_words.txt\". For example, \"the\" appears a lot in both negative and positive movie reviews. These words would interfere with our classification result so we need to remove them before do anything further. To do that, we can pass it as a parameter to <code>CountVectorizer</code> to remove the stopped words from the tokens in all texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst']\n"
     ]
    }
   ],
   "source": [
    "stop_words_file = \"../data_set/movies_reviews/stop_words.txt\"\n",
    "f = open(stop_words_file, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "stopwords = []\n",
    "for line in f:\n",
    "    stopwords.append(line.strip())\n",
    "    \n",
    "f.close()\n",
    "\n",
    "print(stopwords[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of count is: (2010, 39374)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vector = CountVectorizer(stop_words=stopwords)\n",
    "text_ls = pos_ls+neg_ls+test_ls\n",
    "vector.fit(text_ls)\n",
    "\n",
    "# learn a vocabulary dictionary of all tokens in the raw documents\n",
    "voc_dic = vector.vocabulary_\n",
    "\n",
    "# produce counts of occurrences of each word in each document\n",
    "counts = vector.transform(text_ls)\n",
    "print(\"The shape of count is: \"+str(counts.shape))\n",
    "test_counts = counts[-5:].toarray()\n",
    "counts = counts[:-5].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Add class labels\n",
    "We can add the labels pos or neg to the vector depending on the directory of the movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2005,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1-1005 are positive reviews so our label is 1\n",
    "Y_orig = np.ones((1005,)) \n",
    "\n",
    "# 1005-2005 are negative reviews so our label is 0\n",
    "Y_orig = np.concatenate((Y_orig, np.zeros((1000,)))) \n",
    "Y = Y_orig.reshape(-1)\n",
    "\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, Y, test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Classify with Naive Bayse Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Test accuracy and predict new reviews\n",
    "We first test our model with test data and obtain the accuracy. Then we find 5 new movie reviews on [rottentomatoes](https://www.rottentomatoes.com/m/over_the_moon_2020) which include a star rating out of 5 that tells us whether it's positive review or negative review, and try to classify them into positive/negative using our classifier. The test file is [here](https://drive.google.com/file/d/1UyZTR4ezhFnYmusAl6gqij83yT-4Ziq0/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8089700996677741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual class:  [1, 1, 0, 0, 1]\n",
      "Predicted class:  [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "Y_pre = [1,1,0,0,1]\n",
    "predicted = clf.predict(test_counts)\n",
    "\n",
    "print(\"Actual class: \", Y_pre)\n",
    "print(\"Predicted class: \",predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among 5 new movie reviews, our classifier correctly classifies 3 of them, with an accuracy of 0.6. I suppose it might have to do with the ambiguity of the review, for example, some negative review that I chose might be full with praise (constructive criticism). It in general performs well with the test dataset (accuracy > 0.8) and longer review might be better for classification as it provides more evidence to classify."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
